---
title: "Addition Notes on Random Numbers"
author: Yuk Tung Liu
output: html_document
fontsize: 18pt
---
<style type="text/css">

body, td {
   font-size: 18px;
}
code.r{
  font-size: 18px;
}
pre {
  font-size: 18px
}
</style>

<!-- script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "all" } }
});
</script -->

```{r setoptions, echo=FALSE}
knitr::opts_chunk$set(comment = NA)
```

### Random Numbers and Pseudo Random Numbers 

You probably have come across fill-in-the-blank exercises similar to the following:  

a) 1, 2, 4, 8, 16, 32, __  
b) 1, 4, 9, 16, 25, __
c) 3, 4, 7, 11, 18, 29, __  

Can you fill in the missing blanks? They are 64, 36, and 47. In the first sequence, each number is twice of the previous one. The second sequence is a square sequence: 1^2^, 2^2^, 3^2^, 4^2^, 5^2^, 6^2^. For the third sequence, the 3rd number and beyond are obtained by the sum of the previous two numbers: 7=4+3, 11=7+4, 18=11+7, 29=18+11, 29+18=47. The numbers in the above 3 sequences are not random, in the sense that they follow a certain rule. You can predict the numbers in the sequence by just observing a few of them. 

```{r, echo=FALSE}
# set seed for demo
set.seed(39135)
```

By contrast, sequences of random numbers do not follow any pattern in the appearance of numbers. Take for example, the outcomes of throwing a die. If you throw a die 10 times, you may get a sequence such as 1, 6, 2, 1, 5, 6, 3, 3, 3, 6. You cannot predict what the next outcome will be based on the observed outcomes. Computers can generate numbers that appear to be random. For example, the commands
```{r}
rnorm(10)
```
generates 10 numbers that appear to be random. It is not easy to predict what number you will get the next time you run `rnorm()` again. However, the seemingly random numbers generated by computers are not truly random. They are generated by somewhat complicated algorithms. If you figure out the algorithm, you will be able to predict what the next number will be. For example, I can tell you that the above 10 numbers are generated using R's `rnorm()` function with a seed number 39135. The same 10 numbers can be reproduced by opening an R console, typing `set.seed(39135)` and then `rnorm(10)`. To find out what the next number will be, just type 
```{r}
rnorm(1)
```
For this reason, these numbers are called *pseudo random numbers*. Even though pseudo random numbers are not true random numbers, they are easy to generate and share many statistical properties of true random numbers. They are widely used in many applications to simulate random numbers. For simplicity, we do not distinguish random numbers and pseudo random numbers hereafter. 

### Random Number Distribution

By definition, the outcomes of random numbers cannot be predicted, but in many cases a particular sequence of random numbers satisfy well-defined statistical properties. For example, suppose you throw a die many times and record the outcomes. Even though you cannot predict the outcome of each throw, when you examine the outcomes you find that each of the number '1', '2', '3', '4', '5', and '6' occurs roughly equal number of times. We say that these random numbers follow a uniform distribution. The distribution can be visualized by a histogram:
```{r, echo=FALSE}
hist(sample(1:6,1e5,replace=TRUE), freq=FALSE, breaks=0.5:6.5, main="Simulated Histrogram of Throwing a Fair Die 100,000 times", xlab="Outcome of Throwing a Die")
```

This histogram is generated using R's random number generators to simulate throwing a fair die 100,000 times. We will talk about using R to do simulations later in the course. We see that the fraction of occurrence of each number is about 1/6, exactly what is expected for a fair die.

By contract, the random numbers generated by the `rnorm()` function do not look like that. Let's examine 100 random numbers generated by the `rnorm()` function:
```{r}
set.seed(389248467)
x <- rnorm(100)
x
```
These numbers are not uniformly distributed. For example, only 4 numbers are larger than 2. To see the distribution, we plot the histogram: 

```{r, echo=FALSE}
hist(x,freq=FALSE,breaks=seq(-3,3,0.5))
```

This shows that most of the numbers are in the range (-1,1). The farther away it is from 0, the less fraction of numbers we tend to see. The distribution follows roughly the standard normal curve. This is because the `rnorm()` function simulates random numbers drawn from the standard normal distribution (mean=0 and standard deviation=1). You can think of it as follows. Suppose there is a box that contains trillions of tickets, each ticket has a number written on it. The numbers in the box follows the standard normal distribution. That is to say, the fraction of the tickets with numbers between $Z_1$ and $Z_2$ is given by the area under the normal curve between $Z=Z_1$ and $Z=Z_2$. For example, the fraction of tickets with numbers between $Z=0$ and $Z=0.1$ is given by the area of the shaded black region in the plot below; the fraction of the tickets with numbers between $Z=0.1$ and $Z=0.2$ is given by the area of the shaded red region; the fraction between 0.2 and 0.3 is given by the area of the shaded green region; the fraction between 0.3 and 0.4 is given by the area of the shaded blue region; and so on.

```{r, echo=FALSE}
p1=0
p2=0.1
p=seq(0,0.4,0.1)
xmin=-3
xmax=3
npoly=50
curve(dnorm(x),xlim=c(xmin,xmax),xlab="Z",ylab="dnorm(Z)") 
for (i in 1:4) {
    cord.x <- c(p[i],seq(p[i],p[i+1],length.out=npoly),p[i+1]) 
    cord.y <- c(0,dnorm(seq(p[i],p[i+1],length.out=npoly)),0) 
    polygon(cord.x,cord.y,col=i)
}
#text(p1-0.2,0.01,labels="0.5",font=3,family="serif",cex=1.5)
#text(p2+0.25,0.01,labels="0.7",font=3,family="serif",cex=1.5)
```

Recall that the total area under the standard normal curve (actually for *all* probability density curves) is 1, meaning that all of the numbers in the box are between $-\infty$ and $\infty$. However, since the curve falls rapidly as we move away from $Z=0$, the area under the curve beyond large values of $|Z|$ are small, meaning that the fractions of tickets with large values of $|Z|$ is small. 

Imagine you randomly draw tickets from this box. Since the number of tickets is large, it doesn't really matter if you draw them with or without replacement. Since there are more tickets in the central region, the majority of the tickets you draw will have numbers in the central region but ocassionally you will get larger values of |Z|. The `rnorm()` function simulates the random draws from this hypothetical "standard normal box". 

### Random Numbers From Transforming and Combining Other Random Numbers

Random numbers can also be created from existing random numbers. For example, a new set of random numbers can be generated from the random numbers stored in x above: 
```{r}
y <- x^2
y
```
Even though the new 100 numbers are related to the random numbers in x, they are still random numbers: you cannot predict what the next number will be based on the 100 numbers shown here. However, the statistical property of this new set of random numbers is different from that of x. For example, there are no negative numbers in the new set. The histogram of y is very different from x: 

```{r echo=FALSE}
hist(y, freq=FALSE, breaks=seq(0,8.5,0.5))
```

While x follows the standard normal distribution, y follows another distribution. The distribution of y can be calculated theoretically. It is called the $\chi^2$ distribution with one degree of freedom. You can think of doing the experiment of drawing 100 numbers from the hypothetical "standard normal box". Instead of recording the numbers on the tickets, you record the square of the numbers on the tickets. 

Many other sets of random numbers can be created by transforming the random numbers in x. For example, `z1 <- x^3`, `z2<- 1/x`, `z3 <- sin(x)`, ... etc. In each case, the new set of random numbers follow a different distribution. In addition to transformation of one set of random numbers, we can also create a new set of random numbers by combining different sets of random numbers. For example, suppose we draw 100 random numbers from a hypothetical "standard normal box", then draw another 100 random numbers, and then draw another 100 numbers. We can simulate this experiment using the following R commands: 
```{r}
set.seed(764856)
x1 <- rnorm(100)
x2 <- rnorm(100)
x3 <- rnorm(100)
```
To see the outcomes of this experiment, we type  
```{r}
x1
x2
x3
```
We can combine them into a new set of random numbers in the following way. Take the first element of x1, x2 and x3: `r x1[1]`, `r x2[1]` and `r x3[1]`. Square them, take the sum and write down the result as the first random number in our new set:  
(`r x1[1]`)^2^ + (`r x2[1]`)^2^ + (`r x3[1]`)^2^ = `r x1[1]^2+x2[1]^2+x3[1]^2` <--- first random number in our new set. 

Do the same operation for the other 99 elements. In R, this can be done by the command
```{r}
y <- x1^2 + x2^2 + x3^2
y
```
We have just generated a new set of 100 random numbers and stored them in the variable y. We can also do it directly using the following commands:
```{r}
set.seed(764856)
y2 <- rnorm(100)^2 + rnorm(100)^2 + rnorm(100)^2
```
We can verify that y and y2 are the same: 
```{r}
y-y2
```
The new set of random numbers y follow a different distribution than any of x1, x2, and x3. It is also different from the distribution of x1^2, x2^2 and x3^2. The resulting distribution can be calculated theoretically. They are called the $\chi^2$ distribution with 3 degrees of freedom.

In Statistics, we encounter random numbers following different distributions. Some well-known distributions, e.g. $\chi^2$, t and F, in statistics arise from transforming and combining different sets of random numbers following a particular distribution.  

<br />
<br />
<br />
